tags_list = [
    "Romance", "Adventure", "Fantasy", "Sci-Fi", "Drama",
    "Mystery", "Comedy", "Horror", "One-Shot", "Series",
    "AU", "Fluff", "Angst", "Slow Burn", "Family",
    "Friendship", "Magic", "Supernatural", "Action", "Slice of Life"
]

num_entries = 100  # Number of fanfic entries
data = []
for _ in range(num_entries):
    num_tags = random.randint(1, 5)  # Random number of tags per fanfic
    tags = random.sample(tags_list, num_tags)
    num_hits = random.randint(50, 500)  # Random popularity score

    data.append({"tags": tags, "num_hits": num_hits})

df = pd.DataFrame(data)

unwanted_tags = ["One-Shot", "AU"]  # Tags to exclude
min_support = 5
min_occurrences = 10  
output_df = process_fanfics(df, unwanted_tags, min_support, min_occurrences)
print(output_df)

#i use this on google colab with files in .csv; feel free to do so also, since it has a lot of space to process the data; in my case, there are more than 140000 tags to be analysed and my laptop cant do it 
